{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Unbiased performance estimates for your classifiers\n",
    "\n",
    "*This notebook first appeared as a [blog post](http://betatim.github.io/posts/unbiased-performance/) on [Tim Head](//betatim.github.io)'s blog.*\n",
    "\n",
    "*License: [MIT](http://opensource.org/licenses/MIT)*\n",
    "\n",
    "*(C) 2016, Tim Head.*\n",
    "*Feel free to use, distribute, and modify with the above attribution.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> This is an [interactive blog post](https://betatim.github.io/posts/really-interactive-posts/), you can modify and run the code directly from your browser. To\n",
    "> see any of the output you have to run each of the cells.\n",
    "\n",
    "In particle physics applications (like the [flavour of physics competition](https://www.kaggle.com/c/flavours-of-physics/) on kaggle) we often optimise\n",
    "the decision threshold of the classifier used to select events.\n",
    "\n",
    "Recently we discussed (once again) the question of how to optimise the\n",
    "decision threshold in an unbiased way. So I decided to build a small\n",
    "toy model to illustrate some points and make the discussion more concrete.\n",
    "\n",
    "What happens if you optimise this parameter via cross-validation and use\n",
    "the classifier performance estimated on each held-out subset as an estimate\n",
    "for the true performance?\n",
    "\n",
    "If you studied up on ML, then you know the answer: it will most likely be\n",
    "a optimistic estimate, not an unbiased one.\n",
    "\n",
    "Below some examples of optimising hyper-parameters on a dataset where the\n",
    "true performance is 0.5, aka there is no way to tell one class from the other.\n",
    "This is convenient because by knowing the true performance, we can evaluate\n",
    "whether or not our estimate is biased.\n",
    "\n",
    "After optimising some standard hyper-parameters we will build two meta-estimators\n",
    "that help with finding the best decision threshold via the normal `GridSearchCV`\n",
    "interface.\n",
    "\n",
    "To sweeten the deal, here a gif of Benedict Cumberbatch pretending to be unbiased:\n",
    "\n",
    "<img src=\"http://i.gifntext.com/35465-neutral-indifferent-unbiased-neutral.gif\" />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%config InlineBackend.figure_format='retina'\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy as sp\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.base import BaseEstimator, TransformerMixin, ClassifierMixin, MetaEstimatorMixin\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.utils import check_random_state"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Uninformative data\n",
    "\n",
    "This data set uses a mix of gaussian and uniformly distributed features and assigns\n",
    "the class label purely at random. Therefore we know that the true accuracy of any\n",
    "classifier on this sample is 0.5.\n",
    "\n",
    "Conclude something from that Sherlock!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def data(N=1000, n_features=100, random_state=None):\n",
    "    rng = check_random_state(random_state)\n",
    "    gaussian_features = n_features//2\n",
    "\n",
    "    return (np.hstack([rng.normal(size=(N, gaussian_features)),\n",
    "                       rng.uniform(size=(N, n_features-gaussian_features))]),\n",
    "            np.array(rng.uniform(size=N)>0.5, dtype=int))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X, y = data(200, random_state=1)\n",
    "# set aside data for final (unbiased)performance evaluation\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.4, random_state=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyper-parameters\n",
    "\n",
    "To kick things of, let's estimate a bunch of hyper-parameters for a typical random forest\n",
    "based model. We keep the testing data to the side for the moment and use only\n",
    "the training set. `GridSearchCV` will evaluate the performance of the classifier\n",
    "using three folds. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "param_grid = {'max_depth': [1, 2, 5, 10, 20, 30, 40, 50],\n",
    "              'max_features': [4, 8, 16, 32, 64, 80, 100]}\n",
    "\n",
    "rf = RandomForestClassifier(random_state=94)\n",
    "grid = GridSearchCV(rf,\n",
    "                    param_grid=param_grid,\n",
    "                    n_jobs=6,\n",
    "                    verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "_ = grid.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The best parameters found and their score:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score: 0.6167\n",
      "Best params: {'max_features': 64, 'max_depth': 2}\n",
      "Score on a totally fresh dataset: 0.5625\n"
     ]
    }
   ],
   "source": [
    "print(\"Best score: %.4f\"%grid.best_score_)\n",
    "print(\"Best params:\", grid.best_params_)\n",
    "print(\"Score on a totally fresh dataset:\", grid.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The best accuracy we found is around 0.62 with `max_depth=1` and `max_features=8`.\n",
    "As we created the dataset with out any informative features we know that the true score\n",
    "of any classifier is 0.5. Therefore this is either a fluctuation (because we don't measure\n",
    "the score precisely enough) or the score from `GridSearchCV` is biased.\n",
    "\n",
    "You can also see that using a fresh, never seen before sample gives us an estimated\n",
    "accuracy of 0.56.\n",
    "\n",
    "\n",
    "## Bias or no bias?\n",
    "\n",
    "To test this whether the accuracy obtained from `GridSearchCV` is biased or just a\n",
    "fluke let's repeatedly grid-search for the best parameters and look\n",
    "at the average score. For this we generate a brand new dataset each time. The joys\n",
    "of having an infinite stream of data!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def grid_search(n, param_grid, clf=None):\n",
    "    X, y = data(120, random_state=0+n)\n",
    "    if clf is None:\n",
    "        clf = RandomForestClassifier(random_state=94+n)\n",
    "\n",
    "    grid = GridSearchCV(clf,\n",
    "                        param_grid=param_grid,\n",
    "                        n_jobs=6,\n",
    "                        verbose=0)\n",
    "    grid.fit(X, y)\n",
    "    return grid\n",
    "\n",
    "scores = [grid_search(n, param_grid).best_score_ for n in range(40)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average score: 0.5781+-0.0057\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAw8AAAIcCAYAAACw6ZJXAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n39AAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x10ff31ef0>"
      ]
     },
     "metadata": {
      "image/png": {
       "height": 270,
       "width": 391
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(scores, range=(0.45,0.65), bins=15)\n",
    "plt.xlabel(\"Best score per grid search\")\n",
    "plt.ylabel(\"Count\")\n",
    "print(\"Average score: %.4f+-%.4f\" %(np.mean(scores), sp.stats.sem(scores)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see all of the best scores we find are above 0.5 and the average score\n",
    "is close to 0.58, with a small uncertainty.\n",
    "\n",
    "Conclusion: the best score obtained during grid search is not an unbiased\n",
    "estimate of the true performance. Instead it is an optimistic estimate.\n",
    "\n",
    "## Threshold optimisation\n",
    "\n",
    "Next, let's see what happens if we use a different hyper-parameter: the threshold applied\n",
    "to decide which class a sample falls in during prediction time.\n",
    "\n",
    "For this to work in the `GridSearchCV` framework we construct two meta-estimators.\n",
    "\n",
    "The first one is a transformer. It transforms the features of a sample into the\n",
    "output of a classifier.\n",
    "\n",
    "The second one is a very simple classifier, it assigns samples to one of two classes\n",
    "based on a threshold.\n",
    "\n",
    "Combining them in a pipeline we can then use `GridSearchCV` to optimise the threshold\n",
    "as it if was any other hyper-parameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class PredictionTransformer(BaseEstimator, TransformerMixin, MetaEstimatorMixin):\n",
    "    def __init__(self, clf):\n",
    "        \"\"\"Replaces all features with `clf.predict_proba(X)`\"\"\"\n",
    "        self.clf = clf\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        self.clf.fit(X, y)\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        return self.clf.predict_proba(X)\n",
    "\n",
    "\n",
    "class ThresholdClassifier(BaseEstimator, ClassifierMixin):\n",
    "    def __init__(self, threshold=0.5):\n",
    "        \"\"\"Classify samples based on whether they are above of below `threshold`\"\"\"\n",
    "        self.threshold = threshold\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        self.classes_ = np.unique(y)\n",
    "        return self\n",
    "    \n",
    "    def predict(self, X):\n",
    "        # the implementation used here breaks ties differently\n",
    "        # from the one used in RFs:\n",
    "        #return self.classes_.take(np.argmax(X, axis=1), axis=0)\n",
    "        return np.where(X[:, 0]>self.threshold, *self.classes_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With these two wrappers we can use `GridSearchCV` to find the 'optimal'\n",
    "threshold. We use a different parameter grid that only varies the\n",
    "classifier threshold. You can experiment with optimising all three\n",
    "hyper-parameters in one go if you want to by uncommenting the `max_depth`\n",
    "and `max_features` lines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average score: 0.5750+-0.0070\n"
     ]
    }
   ],
   "source": [
    "pipe = make_pipeline(PredictionTransformer(RandomForestClassifier()),\n",
    "                     ThresholdClassifier())\n",
    "\n",
    "pipe_param_grid = {#'predictiontransformer__clf__max_depth': [1, 2, 5, 10, 20, 30, 40, 50],\n",
    "                   #'predictiontransformer__clf__max_features': [8, 16, 32, 64, 80, 100],\n",
    "                   'thresholdclassifier__threshold': np.linspace(0, 1, num=100)}\n",
    "\n",
    "grids = [grid_search(n,\n",
    "                     clf=pipe,\n",
    "                     param_grid=pipe_param_grid) for n in range(10)]\n",
    "scores = [g.best_score_ for g in grids]\n",
    "print(\"Average score: %.4f+-%.4f\" %(np.mean(scores), sp.stats.sem(scores)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "As we expected the average score is larger than 0.5. This is why you should almost always\n",
    "use a completely fresh dataset to estimate the performance of your classifier.\n",
    "\n",
    "If you enjoyed this post, get in touch on twitter @[betatim](//twitter.com/betatim)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
